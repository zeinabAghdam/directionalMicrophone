{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying CNN model on the spectogram of EEG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import pickle \n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import random \n",
    "import pandas as pd \n",
    "import scipy.io as sio\n",
    "import csv\n",
    "import os\n",
    "from dplf import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai.transforms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-94ce375e95cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_learner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai.transforms'"
     ]
    }
   ],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"/home/zeinab.schaefer/codes/dataDMSpect/DMdata2/\"\n",
    "npyDir = \"/home/zeinab.schaefer/codes/dataDMSpect/npySpectData/\"\n",
    "numSubjects = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the name of the files \n",
    "# the form is FARAH_sub0XY_LS(1/4)_tr(1:4)\n",
    "# 16 subjects with LS1 and LS4, subject 17 has only LS1\n",
    "# LS1:Loud speaker to the left \n",
    "# LS4:Loud speaker to the right \n",
    "fns = []\n",
    "labels = []\n",
    "for subject in range(1,numSubjects+1):\n",
    "    for spk in [1,4]:\n",
    "        for trial in range(1,4+1):\n",
    "            dt = []\n",
    "            fn = 'FARAH_'+'sub0%0.2d'%subject+'_LS'+str(spk)+'_'+str(trial) + 'spec'\n",
    "            fns.append(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save as .npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_by_name(fname, dtPath, opt):\n",
    "    fpath = dtPath + fname \n",
    "    if opt:\n",
    "        dt = sio.loadmat(fpath)['S']\n",
    "        #dt = dt.transpose()\n",
    "        return dt \n",
    "    else:\n",
    "        dt = sio.loadmat(fpath)['y']\n",
    "        dt = dt.transpose()\n",
    "        return np.delete(dt, 29, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in fns:\n",
    "    dt = read_by_name(fn, dataDir, True)\n",
    "    path = npyDir +fn+'.npy'\n",
    "    np.save(path, dt)\n",
    "    # pd.DataFrame(dt).to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we give only the sujbect number and left or right speaker, and it generated the list of names\n",
    "def gen_nameLists(subjectNumber, speakerSide):\n",
    "    ssides = [1,4]\n",
    "    if speakerSide not in ssides:\n",
    "        print(\"speaker side is 1 or 4\")\n",
    "        #break\n",
    "    \n",
    "    namelists = []\n",
    "    for trial in [1,2]: #range(1,5):\n",
    "        fname = 'FARAH_'+'sub0%0.2d'%subjectNumber+'_LS'+str(speakerSide)+'_'+str(trial)+'spec'\n",
    "        namelists.append(fname)\n",
    "    return namelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = dict()\n",
    "dict_electrode_labels = dict()\n",
    "for subj in range(1,numSubjects+1):\n",
    "    \n",
    "    rspk = gen_nameLists(subj, speakerSide=1)\n",
    "    lspk = gen_nameLists(subj, speakerSide=4)\n",
    "    \n",
    "    for name in rspk:\n",
    "        dict_labels[name] = '+1'\n",
    "        \n",
    "    for name in lspk:\n",
    "        dict_labels[name] = '-1'\n",
    "\n",
    "with open(npyDir + 'dict.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for key, value in dict_labels.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectionalMicrophoneDataset(Dataset):\n",
    "    def __init__(self,path,samples):\n",
    "        # path: the path to the npy files \n",
    "        # subjects: the list of the subjects to be loaded    \n",
    "        self.path = path \n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, indx):\n",
    "        itempath = self.path + self.samples[indx]['fname'] +'.npy'\n",
    "        spectMat = np.load(itempath).T # loads the data \n",
    "        signal_label = self.samples[indx]['label'] # the corresponding label \n",
    "        return {'signal': spectMat, 'label': signal_label}\n",
    "     \n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        signal, label = sample['signal'], sample['label']\n",
    "        dt = torch.from_numpy(signal.transpose())\n",
    "        return {'signal': dt, 'label': label}\n",
    "    \n",
    "    \n",
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, dataset, *transforms):\n",
    "        self.dataset = dataset\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "        for transform in self.transforms:\n",
    "            sample = transform(sample)\n",
    "        return sample\n",
    "\n",
    "\n",
    "def sample_for(subject, spk, trial, label):\n",
    "    fname = 'FARAH_'+'sub0%0.2d'%subject+'_LS'+str(spk)+'_'+str(trial)\n",
    "    return {'fname': fname, 'label': label }\n",
    "\n",
    "def create_dt_samples():\n",
    "    train_samples = []\n",
    "    valid_samples = []\n",
    "    for subject in range(1,18):           \n",
    "        for spk in [1, 4]:\n",
    "            \n",
    "            if spk == 1:\n",
    "                label = 0 # Right    \n",
    "            else:\n",
    "                label = 1 # Left\n",
    "            # randomly take three trials out of four for training\n",
    "            # one trial for testing\n",
    "            all_trials = range(1, 3) # range(1,5)\n",
    "            train_trials = random.sample(all_trials, 1)\n",
    "            valid_trials = np.setdiff1d(all_trials, train_trials)\n",
    "        \n",
    "            \n",
    "            # list of validation names accordingly\n",
    "            for trial in valid_trials:\n",
    "                valid_samples.append(sample_for(subject, spk, trial, label))\n",
    "            \n",
    "            for trial in train_trials:\n",
    "                train_samples.append(sample_for(subject, spk, trial, label))\n",
    "    return (train_samples, valid_samples)\n",
    "\n",
    "def all_samples():\n",
    "    samples = []\n",
    "    for subject in range(1,18):\n",
    "        for spk in [1,4]:\n",
    "            if spk == 1:\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "            for trial in [1,2]:#range(1,5):\n",
    "                samples.append(sample_for(subject, spk, trial, label))\n",
    "    return samples\n",
    "\n",
    "def random_split(samples, train_percent = 80):\n",
    "    random.shuffle(samples)\n",
    "    train_limit = (len(samples) * train_percent) // 100\n",
    "    return samples[:train_limit], samples[train_limit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, valid_samples = create_dt_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, valid_samples = random_split(all_samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv(npyDir+'dict.csv')\n",
    "df.columns = ['subjectName', 'label']\n",
    "df.to_csv(npyDir + 'dict2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subjectName</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FARAH_sub001_LS1_2spec</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FARAH_sub001_LS4_1spec</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FARAH_sub001_LS4_2spec</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FARAH_sub002_LS1_1spec</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>FARAH_sub002_LS1_2spec</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             subjectName  label\n",
       "0           0  FARAH_sub001_LS1_2spec      1\n",
       "1           1  FARAH_sub001_LS4_1spec     -1\n",
       "2           2  FARAH_sub001_LS4_2spec     -1\n",
       "3           3  FARAH_sub002_LS1_1spec      1\n",
       "4           4  FARAH_sub002_LS1_2spec      1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(npyDir+'dict2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.drop('Unnamed: 0', axis = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai.vision\n",
    "import os\n",
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/erl.local/zeinab.schaefer/codes/dataDMSpect/SpectImages/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.fro(path, ds_tfms=tfms, size=24);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fastai.vision.ImageDataBunch.from_df(npyDir, df, size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
